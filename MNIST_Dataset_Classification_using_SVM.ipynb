{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "MNIST_Dataset_Classification_using_SVM.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charlie-aashutosh/charlie/blob/master/MNIST_Dataset_Classification_using_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As8ZH_HWO3dO",
        "colab_type": "text"
      },
      "source": [
        "# MNIST Digits - Classification Using SVM\n",
        "\n",
        "In this notebook, we'll explore the popular MNIST dataset and build an SVM model to classify handwritten digits. http://yann.lecun.com/exdb/mnist/\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHVk0cq9O3dQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "5cebe65e-b42e-4529-f0f0-d9933dc827d8"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gc\n",
        "import cv2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SartxEBhPPuo",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "cb52c420-29eb-430d-a8f7-1a46a8fb03d4"
      },
      "source": [
        "from google.colab import files\n",
        "files=files.upload()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-357fde3d-12d3-4be4-be99-71c30b40550c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-357fde3d-12d3-4be4-be99-71c30b40550c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train.csv to train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiJybGwsO3dU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "e1d94838-6c0d-4588-a556-c25df4906724"
      },
      "source": [
        "# read the dataset\n",
        "digits = pd.read_csv(\"train.csv\")\n",
        "digits.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 42000 entries, 0 to 41999\n",
            "Columns: 785 entries, label to pixel783\n",
            "dtypes: int64(785)\n",
            "memory usage: 251.5 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "46XZnR7bO3dY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "e3d63b68-32c1-4139-f97f-2b179d9c15b5"
      },
      "source": [
        "# head\n",
        "digits.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
              "0      1       0       0       0  ...         0         0         0         0\n",
              "1      0       0       0       0  ...         0         0         0         0\n",
              "2      1       0       0       0  ...         0         0         0         0\n",
              "3      4       0       0       0  ...         0         0         0         0\n",
              "4      0       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M99tXp7mO3db",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8162866-ec50-4846-e4f6-57415e9d2eea"
      },
      "source": [
        "four = digits.iloc[3, 1:]\n",
        "four.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "J3gPXpCjO3de",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "dbbe0bf8-c0e7-4e8e-c083-6fc243763312"
      },
      "source": [
        "four = four.values.reshape(28, 28)\n",
        "plt.imshow(four, cmap='gray')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5f899e2668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qG7hyuQ9O3dh",
        "colab_type": "text"
      },
      "source": [
        "#### Side note: Indexing Recall ####\n",
        "`list =    [0, 4, 2, 10, 22, 101, 10]` <br>\n",
        "`indices = [0, 1, 2, 3, ...,        ]` <br>\n",
        "`reverse = [-n           -3  -2   -1]` <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzAEJpJuO3dj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "e8bbf809-4dc8-4d19-9469-e83e97bf2a45"
      },
      "source": [
        "# visualise the array\n",
        "print(four[5:-5, 5:-5])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0 220 179   6   0   0   0   0   0   0   0   0   9  77   0   0   0   0]\n",
            " [  0  28 247  17   0   0   0   0   0   0   0   0  27 202   0   0   0   0]\n",
            " [  0   0 242 155   0   0   0   0   0   0   0   0  27 254  63   0   0   0]\n",
            " [  0   0 160 207   6   0   0   0   0   0   0   0  27 254  65   0   0   0]\n",
            " [  0   0 127 254  21   0   0   0   0   0   0   0  20 239  65   0   0   0]\n",
            " [  0   0  77 254  21   0   0   0   0   0   0   0   0 195  65   0   0   0]\n",
            " [  0   0  70 254  21   0   0   0   0   0   0   0   0 195 142   0   0   0]\n",
            " [  0   0  56 251  21   0   0   0   0   0   0   0   0 195 227   0   0   0]\n",
            " [  0   0   0 222 153   5   0   0   0   0   0   0   0 120 240  13   0   0]\n",
            " [  0   0   0  67 251  40   0   0   0   0   0   0   0  94 255  69   0   0]\n",
            " [  0   0   0   0 234 184   0   0   0   0   0   0   0  19 245  69   0   0]\n",
            " [  0   0   0   0 234 169   0   0   0   0   0   0   0   3 199 182  10   0]\n",
            " [  0   0   0   0 154 205   4   0   0  26  72 128 203 208 254 254 131   0]\n",
            " [  0   0   0   0  61 254 129 113 186 245 251 189  75  56 136 254  73   0]\n",
            " [  0   0   0   0  15 216 233 233 159 104  52   0   0   0  38 254  73   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  18 254  73   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  18 254  73   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   5 206 106   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr0LlnZ_O3dn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "c5a9c4e2-c795-45e1-fbd0-3e3dcb197eed"
      },
      "source": [
        "# Summarise the counts of 'label' to see how many labels of each digit are present\n",
        "digits.label.astype('category').value_counts()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    4684\n",
              "7    4401\n",
              "3    4351\n",
              "9    4188\n",
              "2    4177\n",
              "6    4137\n",
              "0    4132\n",
              "4    4072\n",
              "8    4063\n",
              "5    3795\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfT1IgnoO3dr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "364f3df5-05c4-4755-d2d3-634ebe37e91d"
      },
      "source": [
        "# Summarise count in terms of percentage \n",
        "100*(round(digits.label.astype('category').value_counts()/len(digits.index), 4))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    11.15\n",
              "7    10.48\n",
              "3    10.36\n",
              "9     9.97\n",
              "2     9.95\n",
              "6     9.85\n",
              "0     9.84\n",
              "4     9.70\n",
              "8     9.67\n",
              "5     9.04\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n79q3IOO3dt",
        "colab_type": "text"
      },
      "source": [
        "Thus, each digit/label has an approximately 9%-11% fraction in the dataset and the **dataset is balanced**. This is an important factor in considering the choices of models to be used, especially SVM, since **SVMs rarely perform well on imbalanced data** (think about why that might be the case).\n",
        "\n",
        "Let's quickly look at missing values, if any."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8BTv4CTO3du",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "a2e5f30c-1260-4fc8-dd88-9d161a26b2f4"
      },
      "source": [
        "# missing values - there are none\n",
        "digits.isnull().sum()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label       0\n",
              "pixel0      0\n",
              "pixel1      0\n",
              "pixel2      0\n",
              "pixel3      0\n",
              "           ..\n",
              "pixel779    0\n",
              "pixel780    0\n",
              "pixel781    0\n",
              "pixel782    0\n",
              "pixel783    0\n",
              "Length: 785, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFia47wkO3dx",
        "colab_type": "text"
      },
      "source": [
        "Also, let's look at the average values of each column, since we'll need to do some rescaling in case the ranges vary too much."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "SgFEfDp8O3dx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "79e7f57a-ca7b-4e1a-8f2f-f898646ebec2"
      },
      "source": [
        "# average values/distributions of features\n",
        "description = digits.describe()\n",
        "description"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.00000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.00000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.00000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.456643</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00300</td>\n",
              "      <td>0.011190</td>\n",
              "      <td>0.005143</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000381</td>\n",
              "      <td>0.001310</td>\n",
              "      <td>0.010548</td>\n",
              "      <td>0.027262</td>\n",
              "      <td>0.050905</td>\n",
              "      <td>0.066405</td>\n",
              "      <td>0.129571</td>\n",
              "      <td>...</td>\n",
              "      <td>3.772524</td>\n",
              "      <td>2.748905</td>\n",
              "      <td>1.796452</td>\n",
              "      <td>1.089905</td>\n",
              "      <td>0.563190</td>\n",
              "      <td>0.239571</td>\n",
              "      <td>0.093524</td>\n",
              "      <td>0.024833</td>\n",
              "      <td>0.000857</td>\n",
              "      <td>0.001405</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006143</td>\n",
              "      <td>0.035833</td>\n",
              "      <td>0.082357</td>\n",
              "      <td>0.114905</td>\n",
              "      <td>0.178714</td>\n",
              "      <td>0.301452</td>\n",
              "      <td>0.413643</td>\n",
              "      <td>0.513667</td>\n",
              "      <td>0.558833</td>\n",
              "      <td>0.677857</td>\n",
              "      <td>0.60281</td>\n",
              "      <td>0.489238</td>\n",
              "      <td>0.340214</td>\n",
              "      <td>0.219286</td>\n",
              "      <td>0.117095</td>\n",
              "      <td>0.059024</td>\n",
              "      <td>0.02019</td>\n",
              "      <td>0.017238</td>\n",
              "      <td>0.002857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.887730</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.56812</td>\n",
              "      <td>1.626927</td>\n",
              "      <td>1.053972</td>\n",
              "      <td>0.043916</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.078072</td>\n",
              "      <td>0.232634</td>\n",
              "      <td>1.131661</td>\n",
              "      <td>2.310396</td>\n",
              "      <td>3.121847</td>\n",
              "      <td>3.259128</td>\n",
              "      <td>4.992894</td>\n",
              "      <td>...</td>\n",
              "      <td>26.957829</td>\n",
              "      <td>22.879248</td>\n",
              "      <td>18.595109</td>\n",
              "      <td>14.434439</td>\n",
              "      <td>10.517823</td>\n",
              "      <td>6.469315</td>\n",
              "      <td>3.976306</td>\n",
              "      <td>1.846016</td>\n",
              "      <td>0.139556</td>\n",
              "      <td>0.287891</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.949803</td>\n",
              "      <td>2.350859</td>\n",
              "      <td>3.934280</td>\n",
              "      <td>4.543583</td>\n",
              "      <td>5.856772</td>\n",
              "      <td>7.219742</td>\n",
              "      <td>8.928286</td>\n",
              "      <td>10.004069</td>\n",
              "      <td>10.129595</td>\n",
              "      <td>11.254931</td>\n",
              "      <td>10.69603</td>\n",
              "      <td>9.480066</td>\n",
              "      <td>7.950251</td>\n",
              "      <td>6.312890</td>\n",
              "      <td>4.633819</td>\n",
              "      <td>3.274488</td>\n",
              "      <td>1.75987</td>\n",
              "      <td>1.894498</td>\n",
              "      <td>0.414264</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>116.00000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>216.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>157.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>243.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>177.000000</td>\n",
              "      <td>231.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.00000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>253.00000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              label   pixel0   pixel1  ...  pixel781  pixel782  pixel783\n",
              "count  42000.000000  42000.0  42000.0  ...   42000.0   42000.0   42000.0\n",
              "mean       4.456643      0.0      0.0  ...       0.0       0.0       0.0\n",
              "std        2.887730      0.0      0.0  ...       0.0       0.0       0.0\n",
              "min        0.000000      0.0      0.0  ...       0.0       0.0       0.0\n",
              "25%        2.000000      0.0      0.0  ...       0.0       0.0       0.0\n",
              "50%        4.000000      0.0      0.0  ...       0.0       0.0       0.0\n",
              "75%        7.000000      0.0      0.0  ...       0.0       0.0       0.0\n",
              "max        9.000000      0.0      0.0  ...       0.0       0.0       0.0\n",
              "\n",
              "[8 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JBygYeKO3d0",
        "colab_type": "text"
      },
      "source": [
        "You can see that the max value of the mean and maximum values of some features (pixels) is 139, 255 etc., whereas most features lie in much lower ranges  (look at description of pixel 0, pixel 1 etc. above).\n",
        "\n",
        "Thus, it seems like a good idea to rescale the features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFwuJlEiO3d1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "ed5b2025-e69e-4c6b-eff1-25e88838878f"
      },
      "source": [
        "# Creating training and test sets\n",
        "# Splitting the data into train and test\n",
        "X = digits.iloc[:, 1:]\n",
        "Y = digits.iloc[:, 0]\n",
        "\n",
        "# Rescaling the features\n",
        "from sklearn.preprocessing import scale\n",
        "X = scale(X)\n",
        "\n",
        "# train test split with train_size=10% and test size=90%\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.10, random_state=101)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4200, 784)\n",
            "(37800, 784)\n",
            "(4200,)\n",
            "(37800,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzuiSlARO3d4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# delete test set from memory, to avoid a memory error\n",
        "# we'll anyway use CV to evaluate the model, and can use the separate test.csv file as well\n",
        "# to evaluate the model finally\n",
        "\n",
        "# del x_test\n",
        "# del y_test"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJocVX9BO3d7",
        "colab_type": "text"
      },
      "source": [
        "## Model Building\n",
        "\n",
        "Let's now build the model and tune the hyperparameters. Let's start with a **linear model** first.\n",
        "\n",
        "### Linear SVM\n",
        "\n",
        "Let's first try building a linear SVM model (i.e. a linear kernel). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "EDwJz7BdO3d7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "3b5bbd57-4c38-49bd-f921-610c0b730c7d"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "\n",
        "# an initial SVM model with linear kernel   \n",
        "svm_linear = svm.SVC(kernel='linear')\n",
        "\n",
        "# fit\n",
        "svm_linear.fit(x_train, y_train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "bEdjnu6cO3d9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de2320da-4a71-4f55-8267-aa38fdde1cd6"
      },
      "source": [
        "# predict\n",
        "predictions = svm_linear.predict(x_test)\n",
        "predictions[:10]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 3, 0, 0, 1, 9, 1, 5, 0, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaGfxzF9O3eA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "6cb7acf2-ecb4-44b5-b9d6-1bad3e437fec"
      },
      "source": [
        "# evaluation: accuracy\n",
        "# C(i, j) represents the number of points known to be in class i \n",
        "# but predicted to be in class j\n",
        "confusion = metrics.confusion_matrix(y_true = y_test, y_pred = predictions)\n",
        "confusion"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3615,    0,   12,    8,    8,   28,   28,    5,    9,    2],\n",
              "       [   0, 4089,   16,   23,    9,    3,    3,   13,   25,    4],\n",
              "       [  54,   48, 3363,   64,   74,   13,   53,   52,   59,   10],\n",
              "       [  20,   28,  121, 3387,    8,  175,    5,   54,   58,   44],\n",
              "       [  12,   12,   26,    2, 3399,    7,   41,   41,    4,  158],\n",
              "       [  49,   42,   32,  177,   41, 2899,   54,   14,   82,   28],\n",
              "       [  36,   16,   55,    5,   34,   37, 3486,    3,   21,    0],\n",
              "       [   9,   27,   37,   22,   70,   10,    4, 3619,   14,  142],\n",
              "       [  26,   86,   71,  137,   24,  137,   29,   26, 3096,   33],\n",
              "       [  38,   11,   39,   26,  182,   19,    1,  207,   27, 3228]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "DlHVcfx5O3eE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "157fd66a-b525-4083-9b94-c658fa57fd0d"
      },
      "source": [
        "# measure accuracy\n",
        "metrics.accuracy_score(y_true=y_test, y_pred=predictions)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9042592592592592"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBubita8O3eH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "2741a1d7-e481-4715-8f65-22c148b20adb"
      },
      "source": [
        "# class-wise accuracy\n",
        "class_wise = metrics.classification_report(y_true=y_test, y_pred=predictions)\n",
        "print(class_wise)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.95      3715\n",
            "           1       0.94      0.98      0.96      4185\n",
            "           2       0.89      0.89      0.89      3790\n",
            "           3       0.88      0.87      0.87      3900\n",
            "           4       0.88      0.92      0.90      3702\n",
            "           5       0.87      0.85      0.86      3418\n",
            "           6       0.94      0.94      0.94      3693\n",
            "           7       0.90      0.92      0.91      3954\n",
            "           8       0.91      0.84      0.88      3665\n",
            "           9       0.88      0.85      0.87      3778\n",
            "\n",
            "    accuracy                           0.90     37800\n",
            "   macro avg       0.90      0.90      0.90     37800\n",
            "weighted avg       0.90      0.90      0.90     37800\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVNJSSZ2O3eJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee8a0f66-5e2e-4057-a3bf-9d04668f3778"
      },
      "source": [
        "# run gc.collect() (garbage collect) to free up memory\n",
        "# else, since the dataset is large and SVM is computationally heavy,\n",
        "# it'll throw a memory error while training\n",
        "gc.collect()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkkNuluoO3eM",
        "colab_type": "text"
      },
      "source": [
        "### Non-Linear SVM\n",
        "\n",
        "Let's now try a non-linear model with the RBF kernel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukVVS_C6O3eM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "b00d0c87-1776-45f2-c0f1-df9aac611c9a"
      },
      "source": [
        "# rbf kernel with other hyperparameters kept to default \n",
        "svm_rbf = svm.SVC(kernel='rbf')\n",
        "svm_rbf.fit(x_train, y_train)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORtnMsD1O3eO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "549dd866-f332-4668-ae78-41452280b1f0"
      },
      "source": [
        "# predict\n",
        "predictions = svm_rbf.predict(x_test)\n",
        "\n",
        "# accuracy \n",
        "print(metrics.accuracy_score(y_true=y_test, y_pred=predictions))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9250793650793651\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKdD8uBjO3eR",
        "colab_type": "text"
      },
      "source": [
        "The accuracy achieved with a non-linear kernel is slightly higher than a linear one. Let's now do a grid search CV to tune the hyperparameters C and gamma.\n",
        "\n",
        "### Grid Search Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F1zaTsMO3eR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "99a328d1-9520-4418-9aae-5f45281ae81c"
      },
      "source": [
        "# conduct (grid search) cross-validation to find the optimal values \n",
        "# of cost C and the choice of kernel\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = {'C':[1, 10, 100], \n",
        "             'gamma': [1e-2, 1e-3, 1e-4]}\n",
        "\n",
        "# instantiate a model \n",
        "svc_grid_search = svm.SVC(kernel=\"rbf\")\n",
        "\n",
        "# create a classifier to perform grid search\n",
        "clf = GridSearchCV(svc_grid_search, param_grid=parameters, scoring='accuracy')\n",
        "\n",
        "# fit\n",
        "clf.fit(x_train, y_train)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=None, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [1, 10, 100], 'gamma': [0.01, 0.001, 0.0001]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAnBWygQO3eT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "outputId": "de953670-e65f-4eaa-edd5-814643b093f1"
      },
      "source": [
        "# results\n",
        "cv_results = pd.DataFrame(clf.cv_results_)\n",
        "cv_results"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_C</th>\n",
              "      <th>param_gamma</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20.209827</td>\n",
              "      <td>0.200350</td>\n",
              "      <td>2.665971</td>\n",
              "      <td>0.024435</td>\n",
              "      <td>1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
              "      <td>0.719048</td>\n",
              "      <td>0.759524</td>\n",
              "      <td>0.686905</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.726190</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.023450</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.466103</td>\n",
              "      <td>0.079360</td>\n",
              "      <td>1.765304</td>\n",
              "      <td>0.023987</td>\n",
              "      <td>1</td>\n",
              "      <td>0.001</td>\n",
              "      <td>{'C': 1, 'gamma': 0.001}</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>0.921429</td>\n",
              "      <td>0.908333</td>\n",
              "      <td>0.911905</td>\n",
              "      <td>0.923810</td>\n",
              "      <td>0.918095</td>\n",
              "      <td>0.006709</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.437291</td>\n",
              "      <td>0.099046</td>\n",
              "      <td>2.308414</td>\n",
              "      <td>0.027351</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>{'C': 1, 'gamma': 0.0001}</td>\n",
              "      <td>0.876190</td>\n",
              "      <td>0.884524</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.873810</td>\n",
              "      <td>0.883333</td>\n",
              "      <td>0.876905</td>\n",
              "      <td>0.006547</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20.225286</td>\n",
              "      <td>0.150608</td>\n",
              "      <td>2.660775</td>\n",
              "      <td>0.007996</td>\n",
              "      <td>10</td>\n",
              "      <td>0.01</td>\n",
              "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.709524</td>\n",
              "      <td>0.746429</td>\n",
              "      <td>0.744048</td>\n",
              "      <td>0.741667</td>\n",
              "      <td>0.021176</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.481768</td>\n",
              "      <td>0.059401</td>\n",
              "      <td>1.627316</td>\n",
              "      <td>0.017780</td>\n",
              "      <td>10</td>\n",
              "      <td>0.001</td>\n",
              "      <td>{'C': 10, 'gamma': 0.001}</td>\n",
              "      <td>0.941667</td>\n",
              "      <td>0.927381</td>\n",
              "      <td>0.915476</td>\n",
              "      <td>0.910714</td>\n",
              "      <td>0.930952</td>\n",
              "      <td>0.925238</td>\n",
              "      <td>0.011076</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4.315162</td>\n",
              "      <td>0.054495</td>\n",
              "      <td>1.494591</td>\n",
              "      <td>0.010328</td>\n",
              "      <td>10</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>{'C': 10, 'gamma': 0.0001}</td>\n",
              "      <td>0.921429</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.910714</td>\n",
              "      <td>0.920238</td>\n",
              "      <td>0.915476</td>\n",
              "      <td>0.009066</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>20.375010</td>\n",
              "      <td>0.334849</td>\n",
              "      <td>2.693890</td>\n",
              "      <td>0.025576</td>\n",
              "      <td>100</td>\n",
              "      <td>0.01</td>\n",
              "      <td>{'C': 100, 'gamma': 0.01}</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.709524</td>\n",
              "      <td>0.746429</td>\n",
              "      <td>0.744048</td>\n",
              "      <td>0.741667</td>\n",
              "      <td>0.021176</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.468286</td>\n",
              "      <td>0.092629</td>\n",
              "      <td>1.628807</td>\n",
              "      <td>0.015501</td>\n",
              "      <td>100</td>\n",
              "      <td>0.001</td>\n",
              "      <td>{'C': 100, 'gamma': 0.001}</td>\n",
              "      <td>0.938095</td>\n",
              "      <td>0.929762</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.908333</td>\n",
              "      <td>0.929762</td>\n",
              "      <td>0.924048</td>\n",
              "      <td>0.010999</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3.315269</td>\n",
              "      <td>0.037247</td>\n",
              "      <td>1.290883</td>\n",
              "      <td>0.015511</td>\n",
              "      <td>100</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>{'C': 100, 'gamma': 0.0001}</td>\n",
              "      <td>0.908333</td>\n",
              "      <td>0.920238</td>\n",
              "      <td>0.886905</td>\n",
              "      <td>0.890476</td>\n",
              "      <td>0.923810</td>\n",
              "      <td>0.905952</td>\n",
              "      <td>0.015040</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "0      20.209827      0.200350  ...        0.023450                9\n",
              "1       6.466103      0.079360  ...        0.006709                3\n",
              "2       9.437291      0.099046  ...        0.006547                6\n",
              "3      20.225286      0.150608  ...        0.021176                7\n",
              "4       5.481768      0.059401  ...        0.011076                1\n",
              "5       4.315162      0.054495  ...        0.009066                4\n",
              "6      20.375010      0.334849  ...        0.021176                7\n",
              "7       5.468286      0.092629  ...        0.010999                2\n",
              "8       3.315269      0.037247  ...        0.015040                5\n",
              "\n",
              "[9 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_T5R1RxO3eW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c4caa9ad-dc94-4a0e-b41e-87361b4d11fd"
      },
      "source": [
        "# converting C to numeric type for plotting on x-axis\n",
        "cv_results['param_C'] = cv_results['param_C'].astype('int')\n",
        "\n",
        "# # plotting\n",
        "plt.figure(figsize=(16,6))\n",
        "\n",
        "# subplot 1/3\n",
        "plt.subplot(131)\n",
        "gamma_01 = cv_results[cv_results['param_gamma']==0.01]\n",
        "\n",
        "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_test_score\"])\n",
        "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_train_score\"])\n",
        "plt.xlabel('C')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(\"Gamma=0.01\")\n",
        "plt.ylim([0.60, 1])\n",
        "plt.legend(['test accuracy', 'train accuracy'], loc='lower right')\n",
        "plt.xscale('log')\n",
        "\n",
        "# subplot 2/3\n",
        "plt.subplot(132)\n",
        "gamma_001 = cv_results[cv_results['param_gamma']==0.001]\n",
        "\n",
        "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_test_score\"])\n",
        "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_train_score\"])\n",
        "plt.xlabel('C')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(\"Gamma=0.001\")\n",
        "plt.ylim([0.60, 1])\n",
        "plt.legend(['test accuracy', 'train accuracy'], loc='lower right')\n",
        "plt.xscale('log')\n",
        "\n",
        "\n",
        "# subplot 3/3\n",
        "plt.subplot(133)\n",
        "gamma_0001 = cv_results[cv_results['param_gamma']==0.0001]\n",
        "\n",
        "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_test_score\"])\n",
        "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_train_score\"])\n",
        "plt.xlabel('C')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(\"Gamma=0.0001\")\n",
        "plt.ylim([0.60, 1])\n",
        "plt.legend(['test accuracy', 'train accuracy'], loc='lower right')\n",
        "plt.xscale('log')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'mean_train_score'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-0e620776d439>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma_01\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"param_C\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma_01\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean_test_score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma_01\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"param_C\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma_01\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean_train_score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'mean_train_score'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAFpCAYAAAAFs0R/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df5BdZZ3n8fcn3WkIwSQtZhgkmRDLOMi6CNKVkRpxp3SoBcsh1upqZ9wVplTWRXSG2tndUNZaLjNbq1u6+IuylmFQtGaJsxl/RI3LMMDW+Ae6adgsEDAQcdwEUFq8t9G+Dfd293f/uM8Nx5vb3ae7b+iccz6vqlu55zm/nnMv/eE559znOYoIzMyqZNVKV8DM7MXm4DOzynHwmVnlOPjMrHIcfGZWOQ4+M6ucXMEn6TJJhyQdlrSrx/wbJR1Ir0cl1bvmr5N0VNLn0/Rpkr4j6YeSDkr6eGbZqySNZ7b3vuUepJlZ1uBCC0gaAG4CLgWOAvsl7Y2IhzvLRMR1meU/BFzYtZk/A/6+q+yTEXGPpCHgLkmXR8R307yvRsS1iz8cM7OF5WnxbQcOR8TjEdEEdgM75ll+J3B7Z0LSRcCZwN92yiKiERH3pPdN4H5g0+Krb2a2eHmC72zgSGb6aCo7jqQtwFbg7jS9CvgU8KdzbVzSBuAPgLsyxW+X9ICkPZI256ijmVluC57qLtIosCciZtL0NcC+iDgq6biFJQ3Sbh1+NiIeT8XfAm6PiOcl/SvgNuBNPda9GrgaYO3atRede+65fT4UMyu6++677+cRsbG7PE/wPQFkW12bUlkvo8AHM9MXA5dIugY4HRiS9KuI6NwguRl4LCI+3VkhIp7JrH8L8F967Sgibk7rMzIyEmNjYzkOxcyqRNJPepXnCb79wDZJW2kH3ijwhz12cC4wDNzbKYuId2fmXwWMdEJP0p8D64H3dW3nrIh4Kk1eATySo45mZrktGHwRMS3pWuAOYAC4NSIOSroBGIuIvWnRUWB35BjuRdIm4CPAD4H702nw5yPiFuDDkq4ApoFfAFct/rDMzOamMgxL5VNdM+tF0n0RMdJd7p4bZlY5Dj4zqxwHn5lVjoPPzCrHwWdmlePgM7PKcfCZWeU4+Myscvo9SEFl/fjnk/zDM5MrXQ2zUnv5+jX89m++ZNnbcfD1yR/+xfd5auK5la6GWant3L6Z//zPzl/2dhx8fTA7G/zs2ed458gmdm7/rZWujllpnbH2lL5sx8HXB798bprZgFed+RIu/K3hla6OmS3ANzf6oNZoAjB82tAK18TM8nDw9cGx4Fu7eoVrYmZ5OPj6oD7VAmD9Grf4zIrAwdcH9WOnum7xmRWBg68PapPtFp+v8ZkVg4OvD+pTLSRYt8YtPrMicPD1Qb3RZN2pqxlYdfwjNM3s5OPg64Nao+Xre2YF4uDrg3qjyQZf3zMrDAdfH9Td4jMrFAdfH9Tc4jMrFAdfH9QbLTa4xWdWGA6+ZWpOz/Kr56f9Gz6zAnHwLdPEVOfHy27xmRWFg2+ZOt3V1rvFZ1YYDr5lqjXc4jMrGgffMnksPrPicfAt00SjMySVW3xmReHgW6YXBiF1i8+sKBx8y1RrtFg9INYODax0VcwsJwffMnX66UoemcWsKBx8y1RvtNjg63tmheLgW6Zao+k7umYF4+BbJvfTNSueXMEn6TJJhyQdlrSrx/wbJR1Ir0cl1bvmr5N0VNLnM2UXSXowbfOzShfJJL1U0p2SHkv/ntRP6K5PucVnVjQLBp+kAeAm4HLgPGCnpPOyy0TEdRFxQURcAHwO+FrXZv4M+Puusi8A7we2pddlqXwXcFdEbAPuStMnpYig5hafWeHkafFtBw5HxOMR0QR2AzvmWX4ncHtnQtJFwJnA32bKzgLWRcT3IyKALwNvS7N3ALel97dlyk86U60ZmtOzHovPrGDyBN/ZwJHM9NFUdhxJW4CtwN1pehXwKeBPe2zz6BzbPDMinkrvf0o7NHvt62pJY5LGxsfHcxxG/7mfrlkx9fvmxiiwJyJm0vQ1wL6IODrPOnNKrcGYY97NETESESMbN25cWm2XqTMyi1t8ZsUymGOZJ4DNmelNqayXUeCDmemLgUskXQOcDgxJ+hXwmbSdXtv8maSzIuKpdEr8dI46roh6avH5Gp9ZseRp8e0HtknaKmmIdrjt7V5I0rnAMHBvpywi3h0RvxUR59A+3f1yROxKp7LPSnp9upv7HuCbabW9wJXp/ZWZ8pOOR2YxK6YFgy8ipoFrgTuAR4C/joiDkm6QdEVm0VFgdzo9zeMa4BbgMPAj4Lup/OPApZIeA34/TZ+UfI3PrJjynOoSEfuAfV1lH+2a/tgC2/gS8KXM9Bjwmh7LPQO8OU+9VtrEsdGXHXxmReKeG8tQa7Q4bWiAUwY9MotZkTj4lsH9dM2KycG3DO6na1ZMDr5lqLvFZ1ZIDr5lqDdavrFhVkAOvmVoX+Nz8JkVjYNviWZng4mplk91zQrIwbdEv3xumtnwYyXNisjBt0TurmZWXA6+JXrhebpu8ZkVjYNviepTnZFZ3OIzKxoH3xIdG4vP1/jMCsfBt0S1yc7ILG7xmRWNg2+J6o0mEqxzi8+scBx8S1SfarF+zWoGVmmlq2Jmi+TgW6Jao+Xre2YF5eBbonqj6Tu6ZgXl4Fsi99M1Ky4H3xLVG+6na1ZUDr4l8pBUZsXl4FuC5vQsv3p+2i0+s4Jy8C1BfaozQIFbfGZF5OBbgomG++maFZmDbwlqx4LPLT6zInLwLYHH4jMrNgffEhwbmcUtPrNCcvAtQd3X+MwKzcG3BLVGi9UDYu3QwEpXxcyWwMG3BJ1+upJHZjErIgffErifrlmxOfiWoN5osWGNr++ZFZWDbwnqjZbv6JoVmINvCdqnum7xmRWVg2+RIoL6VIsNfp6uWWE5+BZpqjVDc3rW1/jMCixX8Em6TNIhSYcl7eox/0ZJB9LrUUn1VL5F0v2p/KCkD6Tyl2SWPyDp55I+neZdJWk8M+99/Tzg5er00/VdXbPiGlxoAUkDwE3ApcBRYL+kvRHxcGeZiLgus/yHgAvT5FPAxRHxvKTTgYfSuk8CF2TWuQ/4Wma3X42Ia5dxXCdMbbLTXc0tPrOiytPi2w4cjojHI6IJ7AZ2zLP8TuB2gIhoRsTzqfyUXvuT9CrgN4DvLabiK2Viyi0+s6LLE3xnA0cy00dT2XEkbQG2AndnyjZLeiBt4xOptZc1SruFF5myt0t6QNIeSZtz1PFFU2u4xWdWdP2+uTEK7ImImU5BRByJiPOBVwJXSjqzxzq3Z6a/BZyT1rkTuK3XjiRdLWlM0tj4+HhfD2I+vsZnVnx5gu8JINvq2pTKeukOsWNSS+8h4JJOmaTXAoMRcV9muWcyp8e3ABfNsb2bI2IkIkY2btyY4zD6o+5rfGaFlyf49gPbJG2VNEQ73PZ2LyTpXGAYuDdTtknSmvR+GHgDcCiz2rHrgZl1zspMXgE8ku9QXhz1qRZrhwYYGvQvgcyKasG7uhExLela4A5gALg1Ig5KugEYi4hOCI4Cu7uu1b0a+JSkAAR8MiIezMx/J/CWrl1+WNIVwDTwC+CqJRzXCVNLI7OYWXEtGHwAEbEP2NdV9tGu6Y/1WO9O4Px5tvuKHmXXA9fnqddKcD9ds+Lz+doiuZ+uWfE5+BZpwi0+s8Jz8C1S+xqfg8+syBx8izA7G0xMtXyqa1ZwDr5FePa5FrPh3/CZFZ2DbxGOPVZyjU91zYrMwbcInX66wx6E1KzQHHyL4AeJm5WDg28R6lOpxefgMys0B98i1CZ9jc+sDBx8i1BvNJFgnYPPrNAcfItQa7RYv2Y1A6u00lUxs2Vw8C1C3T9eNisFB98i1BtN1vs016zwHHyL0B6ZxcFnVnQOvkWoTfpU16wMHHyLMDHV8o+XzUrAwZdTc3qWXz0/7SGpzErAwZfTC702HHxmRefgy8n9dM3Kw8GXU/3Yg8QdfGZF5+DLqTMkla/xmRWfgy+nuoPPrDQcfDnVfKprVhoOvpzqjRarB8RpQwMrXRUzWyYHX071RpMNpw0heWQWs6Jz8OXkfrpm5eHgy6nWcHc1s7Jw8OU00Wh5yHmzknDw5dQ+1XWLz6wMHHw5RAT1RosNfp6uWSk4+HKYas3QnJl1i8+sJBx8OXR+vOxrfGbl4ODLoTbZ6a7mFp9ZGTj4cnhhZBa3+MzKwMGXw7FBSNe6xWdWBrmCT9Jlkg5JOixpV4/5N0o6kF6PSqqn8i2S7k/lByV9ILPO/0rb7Kz3G6n8FElfTfv6gaRz+nOoS+drfGblMrjQApIGgJuAS4GjwH5JeyPi4c4yEXFdZvkPARemyaeAiyPieUmnAw+ldZ9M898dEWNdu3wvUIuIV0oaBT4BvGuJx9cXdV/jMyuVPC2+7cDhiHg8IprAbmDHPMvvBG4HiIhmRDyfyk/Jub8dwG3p/R7gzVrhkQFqjRZrhwYYGvSVAbMyyPOXfDZwJDN9NJUdR9IWYCtwd6Zss6QH0jY+kWntAXwxneb+h0y4HdtfREwDE8AZPfZ1taQxSWPj4+M5DmPp6lNNt/bMSqTfTZhRYE9EzHQKIuJIRJwPvBK4UtKZada7I+IfA5ek179czI4i4uaIGImIkY0bN/ap+r3VGy2PvGxWInmC7wlgc2Z6UyrrZZR0mtsttfQeoh1yRMQT6d9fAv+d9in1r+1P0iCwHngmRz1PGPfTNSuXPMG3H9gmaaukIdrhtrd7IUnnAsPAvZmyTZLWpPfDwBuAQ5IGJb0sla8G3ko7FEnbvjK9fwdwd0TEUg6uX9ziMyuXBe/qRsS0pGuBO4AB4NaIOCjpBmAsIjohOArs7gqpVwOfkhSAgE9GxIOS1gJ3pNAbAP4O+Iu0zl8CX5F0GPhF2u6KqrvFZ1YqCwYfQETsA/Z1lX20a/pjPda7Ezi/R/kkcNEc+3oO+Od56vVimJ0NJqbc4jMrE/8+YwHPPtdiNvwbPrMycfAtoOZ+umal4+BbgB8kblY+Dr4FdEZm8amuWXk4+BZQSy0+39U1Kw8H3wI8Fp9Z+Tj4FlBvNJHgJac6+MzKwsG3gFqjxfo1qxlYtaIDxJhZHzn4FuB+umbl4+BbgHttmJWPg28BtUbTQ86blYyDbwG1yZZPdc1KxsG3gHrDoy+blY2Dbx7N6VkmmzP+DZ9ZyTj45tF5nq5vbpiVi4NvHu6na1ZODr551CbdT9esjBx886hPdVp8PtU1KxMH3zw8Fp9ZOTn45vHC6Ms+1TUrEwffPGqNJkMDqzhtaGClq2JmfeTgm8dEo8X601YjeWQWszJx8M2jPTKLr++ZlY2Dbx61Rsu/4TMrIQffPOpu8ZmVkoNvHvVGiw1r3OIzKxsH3xwioh18a93iMysbB98cGs0ZmjOz/g2fWQk5+ObQ6a7ma3xm5ePgm0NngIL1vsZnVjoOvjn4QeJm5eXgm0MtDVAwvNYtPrOycfDNwUNSmZWXg28O9XSNz7/jMysfB98cao0Wa4cGGBr0R2RWNrn+qiVdJumQpMOSdvWYf6OkA+n1qKR6Kt8i6f5UflDSB1L5aZK+I+mHqfzjmW1dJWk8s7339etgF8OPlTQrr8GFFpA0ANwEXAocBfZL2hsRD3eWiYjrMst/CLgwTT4FXBwRz0s6HXhI0l6gDnwyIu6RNATcJenyiPhuWu+rEXFtPw5wqepTLYbda8OslPK0+LYDhyPi8YhoAruBHfMsvxO4HSAimhHxfCo/pbO/iGhExD2dZYD7gU1LO4QTo9Zo+vqeWUnlCb6zgSOZ6aOp7DiStgBbgbszZZslPZC28YmIeLJrnQ3AHwB3ZYrfLukBSXskbc51JH1Wb7R8R9espPp95X4U2BMRM52CiDgSEecDrwSulHRmZ56kQdqtw89GxOOp+FvAOWmdO4Hbeu1I0tWSxiSNjY+P9/kwOoOQusVnVkZ5gu8JINvq2pTKehklneZ2Sy29h4BLMsU3A49FxKczyz2TOT2+Bbhoju3dHBEjETGycePGHIeR3+xsMDHVcq8Ns5LKE3z7gW2StqYbEaPA3u6FJJ0LDAP3Zso2SVqT3g8DbwAOpek/B9YDf9K1nbMyk1cAjyzmgPrh2edaRMB6t/jMSmnBu7oRMS3pWuAOYAC4NSIOSroBGIuITgiOArsjIjKrvxr4lKQARPtO7oOSNgEfAX4I3J8e5vP5iLgF+LCkK4Bp4BfAVf040MWouZ+uWaktGHwAEbEP2NdV9tGu6Y/1WO9O4Pwe5UdpB2GvfV0PXJ+nXifKsX66bvGZlZK7JfQwkVp8693iMyslB18PbvGZlZuDrwdf4zMrNwdfDxONJhKsO9XBZ1ZGDr4eao0W69esZtWqnvdfzKzgHHw9uNeGWbk5+HpwP12zcnPw9VCfcovPrMwcfD3UJltsWOMWn1lZOfh68OjLZuXm4OvSnJ5lsjnj3/CZlZiDr0t9Kj1dzc/TNSstB1+Xeuq14Wt8ZuXl4OtSm3Q/XbOyc/B16fTT9e/4zMrLwddlIl3jG/Y1PrPScvB1qfkan1npOfi61BpNhgZWcdrQwEpXxcxOEAdfl/pku59ueg6ImZWQg69LfarpGxtmJefg61JrtNxdzazkHHxd6o2mu6uZlZyDr0u90fKPl81KzsGXERHUGy0/VtKs5Bx8GY3mDM2ZWbf4zErOwZfxwvN03eIzKzMHX8axkVnc4jMrNQdfhoekMqsGB1/GsVNdD1BgVmoOvox6Cj733DArNwdfxgunum7xmZWZgy+j1mixdmiAoUF/LGZl5r/wDD9W0qwaHHwZtUaT4bW+vmdWdg6+jPqU++maVYGDL6PeaLHev+EzK71cwSfpMkmHJB2WtKvH/BslHUivRyXVU/kWSfen8oOSPpBZ5yJJD6ZtflZpyGNJL5V0p6TH0r/D/TrYhdQaTbf4zCpgweCTNADcBFwOnAfslHRedpmIuC4iLoiIC4DPAV9Ls54CLk7lvwPskvTyNO8LwPuBbel1WSrfBdwVEduAu9L0CTczG0xMtdxP16wC8rT4tgOHI+LxiGgCu4Ed8yy/E7gdICKaEfF8Kj+lsz9JZwHrIuL7ERHAl4G3peV2ALel97dlyk+oXz7XIsL9dM2qIE/wnQ0cyUwfTWXHkbQF2ArcnSnbLOmBtI1PRMSTaf2jc2zzzIh4Kr3/KXDmHPu6WtKYpLHx8fEchzE/P0jcrDr6fXNjFNgTETOdgog4EhHnA68ErpTUM8h6Sa3BmGPezRExEhEjGzduXG69M0NSucVnVnZ5gu8JYHNmelMq62WUdJrbLbX0HgIuSetvmmObP0unwp1T4qdz1HHZ3E/XrDryBN9+YJukrZKGaIfb3u6FJJ0LDAP3Zso2SVqT3g8DbwAOpVPZZyW9Pt3NfQ/wzbTaXuDK9P7KTPkJ5bH4zKpjcKEFImJa0rXAHcAAcGtEHJR0AzAWEZ0QHAV2p9PTjlcDn5IUgIBPRsSDad41wJeANcB30wvg48BfS3ov8BPgncs5wLw61/h8V9es/BYMPoCI2Afs6yr7aNf0x3qsdydw/hzbHANe06P8GeDNeerVT/VGk1WCdac6+MzKzj03kk6vjVWrtNJVMbMTzMGX1Dwyi1llOPiSeqPlO7pmFeHgS9xP16w6HHyJW3xm1eHgS+qNpp+1YVYRDj6gOT3LZHPGv+EzqwgHH5nuan6erlklOPhoDzkP7rVhVhUOPqA2mVp8vsZnVgkOPjwWn1nVOPh44RrfsK/xmVWCgw9f4zOrGgcf7V4bQwOrWLN6YKWrYmYvAgcfUJ9s99pIT7g0s5Jz8OF+umZV4+CjfY1vva/vmVWGg4/2XV3f2DCrDgcf7d/x+VTXrDoqH3wRwUSj5dGXzSqk8sHXaM7QnJl1rw2zCql88NU6vTYcfGaVUfng84PEzarHwXfsQeIOPrOqqHzwdU51fY3PrDoqH3x1B59Z5VQ++I6NxedBSM0qo/LBV2+0OP2UQYYGK/9RmFVG5f/a640m69f4NNesSioffLVGk+G1Dj6zKnHwuZ+uWeVUPvgmptxP16xqKh98tUaTDb7GZ1YplQ6+mdlgYqrlfrpmFVPp4Ht2qkWE++maVU2u4JN0maRDkg5L2tVj/o2SDqTXo5LqqfwCSfdKOijpAUnvyqzzvcw6T0r6Rir/PUkTmXkf7dfBdjv2WEnf1TWrlMGFFpA0ANwEXAocBfZL2hsRD3eWiYjrMst/CLgwTTaA90TEY5JeDtwn6Y6IqEfEJZl1/gb4Zma334uIty7nwPI41k/XvTbMKiVPi287cDgiHo+IJrAb2DHP8juB2wEi4tGIeCy9fxJ4GtiYXVjSOuBNwDcWX/3lcT9ds2rKE3xnA0cy00dT2XEkbQG2Anf3mLcdGAJ+1DXrbcBdEfFspuxiSf9X0ncl/aM59nW1pDFJY+Pj4zkO43i1SQ9JZVZF/b65MQrsiYiZbKGks4CvAH8UEbNd6xxrISb3A1si4rXA55ijJRgRN0fESESMbNy4sdciC+pc43OLz6xa8gTfE8DmzPSmVNbLKL8eYp1T2e8AH4mI73fNexntU+nvdMoi4tmI+FV6vw9YnZbru3qjySrBulMdfGZVkif49gPbJG2VNEQ73PZ2LyTpXGAYuDdTNgR8HfhyROzpse13AN+OiOcy6/ymJKX321Mdn8l/SPnV0gAFq1bpRGzezE5SC97VjYhpSdcCdwADwK0RcVDSDcBYRHRCcBTYHRGRWf2dwBuBMyRdlcquiogDmXU+3rXLdwD/WtI0MAWMdm2zb+rup2tWSTpBmfKiGhkZibGxsUWv9y9u+QGTzWm+fs3vnoBamdlKk3RfRIx0l1e650at0XSLz6yCKh189UbLd3TNKqjiwecWn1kVVTb4mtOzTDZnPCSVWQVVNviOdVdb6xafWdVUNvg6j5X0WHxm1VPZ4Ou0+HyNz6x6Kht8nRafHy1pVj2VDb5jLT5f4zOrnMoGn6/xmVVXZYOvPtVkaHAVa1YPrHRVzOxFVt3gm2yxYc1q0kAwZlYhlQ0+99M1q67KBp/76ZpVV3WDb6rp4DOrqMoGX82DkJpVViWDLyKoN5pscPCZVVIlg6/RnKE1E/4Nn1lFVTL4an6QuFmlVTL46o3O83R9qmtWRZUMvppHZjGrtEoGX939dM0qraLB127xrXfwmVVSJYOvMzLLhjU+1TWroooGX5PTTxlkaLCSh29WeZX8y59wP12zSqtk8NUa7qdrVmUVDT730zWrskoGn/vpmlVbNYNvquXf8JlVWOWCb2Y2mJhqDztvZtVUueB7dqpFhPvpmlVZ5YLvWD/dtW7xmVVV5YKvPuWRWcyqrnrB1xmLz9f4zCqrcsFXm+yMzOIWn1lV5Qo+SZdJOiTpsKRdPebfKOlAej0qqZ7KL5B0r6SDkh6Q9K7MOl+S9OPMehekckn6bNrXA5Je16+DBY/FZ2YwuNACkgaAm4BLgaPAfkl7I+LhzjIRcV1m+Q8BF6bJBvCeiHhM0suB+yTdERH1NP/fRsSerl1eDmxLr98BvpD+7YuJqRarBC85dcFDN7OSytPi2w4cjojHI6IJ7AZ2zLP8TuB2gIh4NCIeS++fBJ4GNi6wvx3Al6Pt+8AGSWflqGcutUaT9WtWs2qV+rVJMyuYPMF3NnAkM300lR1H0hZgK3B3j3nbgSHgR5ni/5ROZ2+UdMpi9ifpakljksbGx8dzHEbblpeu5Z+8aqHsNbMy6/f53iiwJyJmsoWpxfYV4MqImE3F1wM/pR2GNwP/Hrgh744i4ua0HiMjI5F3vfe/8RV5FzWzksrT4nsC2JyZ3pTKehklneZ2SFoHfAf4SDp1BSAinkqns88DX6R9Sr3Y/ZmZLVqe4NsPbJO0VdIQ7XDb272QpHOBYeDeTNkQ8HXa1+z2dC1/VvpXwNuAh9KsvcB70t3d1wMTEfHUoo/MzGwOC57qRsS0pGuBO4AB4NaIOCjpBmAsIjohOArsjojsaec7gTcCZ0i6KpVdFREHgL+StBEQcAD4QJq/D3gLcJj2XeE/Ws4Bmpl106/nVDGNjIzE2NjYSlfDzE4yku6LiJHu8sr13DAzc/CZWeU4+Myschx8ZlY5Dj4zqxwHn5lVjoPPzCrHwWdmlePgM7PKKUXPDUnjwE9yLPoy4OcnuDonkuu/sopefyj+MSy2/lsi4rhx6EoRfHlJGuvVfaUoXP+VVfT6Q/GPoV/196mumVWOg8/MKqdqwXfzSldgmVz/lVX0+kPxj6Ev9a/UNT4zM6hei8/MrBrBt9AD0U82kjZLukfSw+lh7H+cyl8q6U5Jj6V/h1e6rvORNCDp/0j6dpreKukH6Xv4ano0wUlL0gZJeyT9UNIjki4u0ncg6br0389Dkm6XdOrJ/h1IulXS05IeypT1/MzT4yk+m47lAUmvy7uf0gdf5oHolwPnATslnbeytVrQNPBvIuI84PXAB1OddwF3RcQ24K40fTL7Y+CRzPQngBsj4pVADXjvitQqv88A/zMizgVeS/tYCvEdSDob+DAwEhGvof3YiFFO/u/gS8BlXWVzfeaXA9vS62rgC7n3EhGlfgEXA3dkpq8Hrl/pei3yGL4JXAocAs5KZWcBh1a6bvPUeVP6j/RNwLdpP1vl58Bgr+/lZHsB64Efk66DZ8oL8R3wwvOpX0r72TrfBv5pEb4D4BzgoYU+c+C/ATt7LbfQq/QtPhbxQPSTkaRzgAuBHwBnxgtPnPspcOYKVSuPTwP/Dug8R/kMoB4R02n6ZP8etgLjwBfT6fotktZSkO8gIp4APgn8P+ApYAK4j2J9Bx1zfeZL/tuuQvAVlqTTgb8B/iQins3Oi/b/4k7KW/KS3go8HRH3rXRdlmEQeB3whYi4EJik67T2JP8OhoEdtAP85cBajj+FLJx+feZVCL5CPqBc0mraofdXEfG1VPyzzPOIzwKeXqn6LeB3gSsk/QOwm/bp7meADZI6jzQ92b+Ho8DRiPhBmt5DOwiL8h38PvDjiBiPiBbwNdrfS5G+g465PvMl/21XIfhyPRD9ZJIesv6XwCMR8V8zs/YCV6b3V9K+9nfSiYjrI2JTRJxD+/O+OyLeDdwDvCMtdtLWHyAifqy7tDIAAADeSURBVAockfTbqejNwMMU5DugfYr7ekmnpf+eOvUvzHeQMddnvhd4T7q7+3pgInNKPL+VvpD5Il0sfQvwKPAj4CMrXZ8c9X0D7eb8A7Qftn4gHcMZtG8YPAb8HfDSla5rjmP5PeDb6f0rgP9N+2Hx/wM4ZaXrt0DdLwDG0vfwDWC4SN8B8B+BHwIPAV8BTjnZvwPgdtrXJFu0W93vneszp33D7Kb0d/0g7TvYufbjnhtmVjlVONU1M/s1Dj4zqxwHn5lVjoPPzCrHwWdmlePgM7PKcfCZWeU4+Myscv4/xrOY0/K5NikAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1152x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztJLB1smO3eZ",
        "colab_type": "text"
      },
      "source": [
        "From the plot above, we can observe that (from higher to lower gamma / left to right):\n",
        "- At very high gamma (0.01), the model is achieving 100% accuracy on the training data, though the test score is quite low (<75%). Thus, the model is overfitting.\n",
        "\n",
        "- At gamma=0.001, the training and test scores are comparable at around C=1, though the model starts to overfit at higher values of C\n",
        "\n",
        "- At gamma=0.0001, the model does not overfit till C=10 but starts showing signs at C=100. Also, the training and test scores are slightly lower than at gamma=0.001.\n",
        "\n",
        "Thus, it seems that the best combination is gamma=0.001 and C=1 (the plot in the middle), which gives the highest test accuracy (~92%) while avoiding overfitting.\n",
        "\n",
        "Let's now build the final model and see the performance on test data.\n",
        "\n",
        "### Final Model\n",
        "\n",
        "Let's now build the final model with chosen hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zLvpWvFO3eZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "23d68ad8-c9df-478d-bd96-484213139806"
      },
      "source": [
        "# optimal hyperparameters\n",
        "best_C = 1\n",
        "best_gamma = 0.001\n",
        "\n",
        "# model\n",
        "svm_final = svm.SVC(kernel='rbf', C=best_C, gamma=best_gamma)\n",
        "\n",
        "# fit\n",
        "svm_final.fit(x_train, y_train)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONPwoBdKO3ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict\n",
        "predictions = svm_final.predict(x_test)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVoUh99vO3ee",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "ecf2d7b9-f529-4346-bf0e-56dff8e12428"
      },
      "source": [
        "# evaluation: CM \n",
        "confusion = metrics.confusion_matrix(y_true = y_test, y_pred = predictions)\n",
        "\n",
        "# measure accuracy\n",
        "test_accuracy = metrics.accuracy_score(y_true=y_test, y_pred=predictions)\n",
        "\n",
        "print(test_accuracy, \"\\n\")\n",
        "print(confusion)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.924973544973545 \n",
            "\n",
            "[[3587    0   10   10    5   15   50   12   25    1]\n",
            " [   0 4108   14   16    5    3    6   18   10    5]\n",
            " [  24   23 3407   65   44    5   36  123   54    9]\n",
            " [   4   21   86 3502    5   89   11   73   76   33]\n",
            " [   3   11   36    7 3450   13   23   43    6  110]\n",
            " [  20   29   14  114   18 3020   79   53   36   35]\n",
            " [  31   12   11    1   14   34 3521   44   25    0]\n",
            " [   4   28   27    8   36    7    1 3739    7   97]\n",
            " [  14   59   32   80   22   97   25   44 3251   41]\n",
            " [  23   13   13   50   98    7    0  176   19 3379]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVVvdB9KO3eg",
        "colab_type": "text"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "The final accuracy on test data is approx. 92%. Note that this can be significantly increased by using the entire training data of 42,000 images (we have used just 10% of that!). \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AwTWMzWiN6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}